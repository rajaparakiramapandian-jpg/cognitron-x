import streamlit as st
from openai import OpenAI
import io
import sys
import matplotlib.pyplot as plt
import plotly.express as px
import utils
from database import db

# --------------------------------------------------
# AGENTIC AI LOGIC
# --------------------------------------------------
def execute_python_code(code, df):
    """
    Executes Python code generated by the agent on the dataframe.
    """
    forbidden_keywords = ["import os", "import subprocess", "import sys", "open(", "remove(", "rmdir("]
    for keyword in forbidden_keywords:
        if keyword in code:
            return "‚ö†Ô∏è Security Alert: The generated code contains forbidden commands and was blocked."

    buffer = io.StringIO()
    old_stdout = sys.stdout
    sys.stdout = buffer
    
    import numpy as np
    from sklearn.linear_model import LinearRegression
    from sklearn.cluster import KMeans
    
    local_vars = {
        "df": df, 
        "plt": plt, 
        "px": px, 
        "st": st,
        "np": np,
        "LinearRegression": LinearRegression,
        "KMeans": KMeans
    }
    
    try:
        exec(code, local_vars, local_vars)
        output = buffer.getvalue().strip()
        result = local_vars.get("result", None)
        
        final_bits = []
        if output:
            final_bits.append(output)
        if result is not None and str(result) not in output:
            final_bits.append(str(result))
            
        return "\n".join(final_bits) if final_bits else None
        
    except Exception as e:
        return f"Error executing code: {str(e)}"
    finally:
        sys.stdout = old_stdout

@st.cache_resource(show_spinner=False)
def get_openai_client(api_key):
    return OpenAI(api_key=api_key)

def query_openai_stream(prompt, df, api_key, model="gpt-5-nano"):
    if not api_key:
        yield "Please provide a valid OpenAI API Key in the sidebar."
        return
        
    try:
        client = get_openai_client(api_key)
        
        # Enhanced Context (Cached)
        context = utils.get_ai_context(df)
        
        system_instruction = f"""
        You are 'RetailAI Pro', a versatile AI Assistant powered by OpenAI. 
        You function as a world-class Business Strategy Consultant and Data Scientist, but you are also capable of answering ANY general question (like ChatGPT).

        **Your Mission:**
        1. **General Assistance**: Answer any question helpfully‚Äîfrom general knowledge to logical reasoning.
        2. **Data Intelligence**: When the query relates to the provided business data (columns: {context['columns']}), perform high-precision analysis.

        **Protocol for Data Queries:**
        If the user asks about the dataframe 'df':
        - State your **Analytical Strategy**.
        - Write Python code inside ```python ... ``` blocks to perform the analysis.
        - Use `st.plotly_chart()` or `plt.show()` for charts.
        - Provide a **Data-Driven Conclusion**.

        **Protocol for General Queries:**
        If the user asks a general question (e.g., "Who is the Prime Minister of India?"), answer directly and conversationally. DO NOT follow the data protocol or write code for non-data questions.

        **Data Context (for reference):**
        - Rows: {context['num_rows']} | Columns: {context['columns']}
        - Sample Data: {context['sample_data']}
        """
        
        completion_args = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": prompt}
            ],
            "stream": True
        }

        if "o1" in model or "gpt-5" in model:
            completion_args["messages"] = [
                {"role": "user", "content": f"SYSTEM INSTRUCTION:\n{system_instruction}\n\nUSER QUERY:\n{prompt}"}
            ]

        response = client.chat.completions.create(**completion_args)
        
        for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
                    
    except Exception as e:
        raise e

def process_agent_response(response_text, df):
    import re
    code_blocks = re.findall(r"```(?:python)?\s*(.*?)```", response_text, re.DOTALL)
    clean_text = re.sub(r"```(?:python)?\s*(.*?)```", "", response_text, flags=re.DOTALL)
    
    execution_results = []
    
    if code_blocks:
        st.info("System: Executing Analysis Model...")
        
        for code in code_blocks:
            code = code.strip()
            res = execute_python_code(code, df)
            execution_results.append(res)
            
            with st.expander("üõ†Ô∏è View Analysis Logic (Technical)"):
                st.code(code, language="python")
                 
        if execution_results:
            results_str = "\\n".join([str(r) for r in execution_results if r and r != "None"])
            if results_str:
                clean_text += f"\\n\\n{results_str}"
            
    return clean_text.strip()

def chatbot_ui():
    utils.set_background()
    st.markdown("### ü§ñ Agentic AI Assistant")
    
    # Check secrets for API Key
    if "OPENAI_API_KEY" in st.secrets:
        st.session_state.openai_api_key = st.secrets["OPENAI_API_KEY"]
        
    # API Key Input
    with st.sidebar:
        st.header("üîë Configuration")
        
        if st.session_state.get("openai_api_key"):
            st.success("API Key Active ‚úÖ")
            st.caption("Mode: ‚ö° OpenAI AI")
             
            with st.expander("üîÑ Change API Key"):
                new_key = st.text_input("New OpenAI Key", type="password", key="new_key_input")
                if st.button("Update Key"):
                    st.session_state.openai_api_key = new_key
                    st.rerun()

            st.info("‚ö° Powered by: **GPT-5 Nano**")
        else:
            st.warning("No API Key Found")
            api_key = st.text_input("Enter OpenAI Key", type="password")
            if api_key:
                st.session_state.openai_api_key = api_key
                st.rerun()
        
        st.divider()
        st.subheader("üßπ Maintenance")
        if st.button("Clear System Cache"):
            st.cache_data.clear()
            st.success("System cache cleared!")
            st.rerun()

        if st.button("üóëÔ∏è Clear Chat History"):
            st.session_state.chat_history = []
            if st.session_state.user_email:
                db.save_chat_history(st.session_state.user_email, "default", [])
            st.rerun()

    # Load History from DB on first run in dashboard
    if st.session_state.user_email and not st.session_state.chat_history:
        st.session_state.chat_history = db.load_chat_history(st.session_state.user_email, "default")

    # Display History
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
        st.divider() 

    # User Input
    user_input = st.chat_input("Ask about your data...")

    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
            
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                if st.session_state.get("openai_api_key"):
                    active_model = st.session_state.get("emergency_fallback_model", "gpt-5-nano")
                    
                    stream = query_openai_stream(
                        user_input, 
                        st.session_state.uploaded_data, 
                        st.session_state.openai_api_key,
                        model=active_model
                    )
                    
                    for chunk in stream:
                        full_response += chunk
                        message_placeholder.markdown(full_response + "‚ñå")
                    message_placeholder.markdown(full_response)
                else:
                    st.error("‚ö†Ô∏è OpenAI API Key is required to use the AI Copilot.")
                    st.info("Please enter your API key in the sidebar configuration.")
                    return 
            except Exception as e:
                error_msg = str(e).lower()
                
                if "429" in error_msg:
                    st.error("üöÄ **API Quota Reached**")
                    if active_model == "gpt-5-nano":
                        if st.button("üîÑ Emergency Switch to gpt-4o-mini"):
                            st.session_state.emergency_fallback_model = "gpt-4o-mini"
                            st.rerun()
                else:
                    st.error(f"‚ö†Ô∏è OpenAI Connection Issue: {str(e)}")
                return
            
            final_display = process_agent_response(full_response, st.session_state.uploaded_data)
            
            if final_display != full_response:
                message_placeholder.markdown(final_display)

        st.session_state.chat_history.append({"role": "assistant", "content": final_display})
        
        if st.session_state.user_email:
            db.save_chat_history(st.session_state.user_email, "default", st.session_state.chat_history)
